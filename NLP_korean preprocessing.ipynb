{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean preprocessing\n",
    "- Record ways to preprocessing korean sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import hanja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By function (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple way to remove special characters -- just define them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_list =  \"‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", >>, `, /, -,∼,=,ㆍ<,>, .,?, !,【,】, …, ◆,%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_list =[]\n",
    "for sen in sentences:\n",
    "    sen_clean = sen.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n",
    "    sen_clean = re.sub('\\s+', ' ', sen_clean)\n",
    "    sen_list.append(sen_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default form : Remove pre-defined special characters and convert multiple spaces to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_list =[]\n",
    "for sen in sentences:\n",
    "    #sen_clean = re.sub(r'  ', ' ', sen_clean)\n",
    "    sen_clean = sen.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n",
    "    sen_clean = re.sub('\\s+', ' ', sen_clean)\n",
    "    sen_clean = '<s ' + sen_clean + ' /s>'\n",
    "    sen_clean = re.sub('\\s+/s>', ' /s>', sen_clean)\n",
    "    sen_clean = re.sub('<s\\s+', '<s ', sen_clean)\n",
    "    sen_list.append(sen_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to seperate sentences by <s(start of sentence) </s(end of sentence) sign, use code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By function (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_PATTERN = re.compile(r'''(([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)(\\.[a-zA-Z]{2,4}))''', re.VERBOSE)\n",
    "URL_PATTERN = re.compile(\"(ftp|http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", re.VERBOSE)\n",
    "MULTIPLE_SPACES = re.compile(' +', re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what to delete in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_other(sentence: str = None) -> str:\n",
    "    \n",
    "    sentence = re.sub(EMAIL_PATTERN, ' ', sentence)\n",
    "    sentence = re.sub(URL_PATTERN, ' ', sentence)\n",
    "    sentence = re.sub(MULTIPLE_SPACES, ' ', sentence)\n",
    "    sentence = sentence.replace(\", )\", \"\")\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove e-mail, url, space using defined pattern above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_chinese(sentence: str = None) -> str:\n",
    "    \n",
    "    sentence = re.sub(\"\\([\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]+\\)\", \"\", sentence)\n",
    "    \n",
    "    if re.search(\"[\\u2E80-\\u2FD5\\u3190-\\u319f\\u3400-\\u4DBF\\u4E00-\\u9FCC\\uF900-\\uFAAD]\", sentence) is not None:\n",
    "        sentence = hanja.translate(sentence, 'substitution')\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove chinese characters. If parentheses are enclosed in front and back, most of them are Korean translations so just remove them without space. If there is another Chinese character, replace it to Korean using `hanja` module( ex. 軍 -> 군 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_special(sentence: str = None) -> str:\n",
    "\n",
    "    sentence = re.sub(\"[.,\\'\\\"’‘”“!?]\", \"\", sentence)\n",
    "    sentence = re.sub(\"[^가-힣0-9a-zA-Z\\\\s]\", \" \", sentence)\n",
    "    sentence = re.sub(\"\\s+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters and leave only Korean, English, numbers. There may be multiple spaces if multiple special characters are attached. Delete it using `sentence = re.sub(\"\\s+\", \" \", sentence)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing_numbers(sentence: str = None) -> str:\n",
    "\n",
    "    sentence = re.sub('[0-9]+', 'NUM', sentence)\n",
    "    sentence = re.sub('NUM\\s+', \"NUM\", sentence)\n",
    "    sentence = re.sub('[NUM]+', \"NUM\", sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If necessary, remove the number as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sent(sentence: str = None) -> str:\n",
    "    \n",
    "    sent_clean = sentence\n",
    "    sent_clean = cleansing_other(sent_clean)\n",
    "    sent_clean = cleansing_chinese(sent_clean)\n",
    "    sent_clean = cleansing_special(sent_clean)\n",
    "    sent_clean = cleansing_numbers(sent_clean)\n",
    "    sent_clean = re.sub('\\s+', ' ', sent_clean)\n",
    "\n",
    "    return sent_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 예시\n",
    "new_sents = []\n",
    "original_sents = {SOURCE_SENTENCE}\n",
    "for sent in original_sents:\n",
    "    new_sent = preprocess_sent(sent)\n",
    "    new_sents.append(new_sent)\n",
    "\n",
    "for ori, new in zip(original_sents, new_sents):\n",
    "    print(\"----------\")\n",
    "    print(\"● 기존: \", ori)\n",
    "    print(\"● 변경: \", new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Mecab\n",
    "- Mecab module provides high quality tokenization and Korean preprocessing.\n",
    "- But mecab is difficult to install jupyter notebook / anaconda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!sudo apt-get install python-dev; pip install konlpy\n",
    "!sudo apt-get install curl\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(paragraph):\n",
    "    mecab = Mecab()\n",
    "    total_nouns = []\n",
    "    \n",
    "    for sentence in paragraph:\n",
    "        nouns= mecab.nouns(sentence) # provide preprocessing\n",
    "        nouns = [n for n in nouns if len(n) >1]\n",
    "        \n",
    "        total_nouns += nouns\n",
    "        \n",
    "    return total_nouns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
