{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm. News classification\n",
    "- Implement news classification using pytorch sentiment analysis.\n",
    "- Using `BalancedNewsCorpus_train.csv` as train set, `BalancedNewsCorpus_test.csv` as test set. It is a balanced data for 9 newspapers among news data from NIKL.\n",
    "- 3 Word2Vec models, 4 fasttext models and 1 Glove models was provided for performance comparison.\n",
    "  - Models were defined by multiple features : space, morph, jamo etc.\n",
    "  - They were not uploaded due to copyright issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install gensim\n",
    "!pip install --ignore-installed hanja\n",
    "!sudo apt-get install python-dev; pip install konlpy\n",
    "!sudo apt-get install curl\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random\n",
    "import tqdm\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "- sentence cleansing has not been processed due to Mecab tokenizer.\n",
    "- `Mecab.nouns` function provide high quality preprocessing for korean sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('BalancedNewsCorpus_train.csv', encoding='utf-8')\n",
    "test_df = pd.read_csv('BalancedNewsCorpus_test.csv', encoding='utf-8')\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer (list):\n",
    "    mecab = Mecab()\n",
    "    total_nouns = []\n",
    "    \n",
    "    for string in list:\n",
    "        nouns= mecab.nouns(string) # provide preprocessing\n",
    "        nouns = [n for n in nouns if len(n) >1]\n",
    "        \n",
    "        total_nouns += nouns\n",
    "        \n",
    "    return total_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build data iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(preprocessing= tokenizer, batch_first = True)\n",
    "LABEL = data.LabelField(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define datafields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "raw_datafields = [(\"filename\", None), # we don't need filename, so we pass in None as the field\n",
    "                 (\"date\", None), (\"NewsPaper\", None),\n",
    "                 (\"Topic\", LABEL), (\"News\", TEXT)]\n",
    "\n",
    "train_data = data.TabularDataset(\n",
    "        path='BalancedNewsCorpus_train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)\n",
    "\n",
    "test_data = data.TabularDataset(\n",
    "        path='BalancedNewsCorpus_test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=raw_datafields)\n",
    "\n",
    "print(vars(test_data.examples[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f\"The example of text vocab : {TEXT.vocab.itos[:10]}\")\n",
    "print(f\"Token index : {LABEL.vocab.stoi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataiterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = data.BucketIterator(\n",
    "    dataset=train_data, batch_size=BATCH_SIZE,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.News), len(x.Topic)))\n",
    "\n",
    "test_iterator = data.BucketIterator(\n",
    "    dataset=test_data, batch_size=BATCH_SIZE,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.News), len(x.Topic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RNN model (LSTM)\n",
    "- Record only the best performance.\n",
    "- LSTM models had the highest test accuracy than other types of CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, \n",
    "                           dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 9\n",
    "N_LAYERS = 1 \n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained embedding (fasttext, morph)\n",
    "- Record only the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "pre_embedding = KeyedVectors.load_word2vec_format('fasttext_morph_300.model', binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "w2v = []\n",
    "\n",
    "for token, idx in tqdm(TEXT.vocab.stoi.items()):\n",
    "    if token in pre_embedding.wv.vocab.keys():\n",
    "        w2v.append(pre_embedding[token])\n",
    "    else:\n",
    "        w2v.append(0.1*np.random.randn(EMBEDDING_DIM))\n",
    "        \n",
    "pretrained_embeddings = torch.FloatTensor(w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained embeddings for weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Optimizer : Adam, lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch.News = batch.News.cuda()\n",
    "        batch.Topic = batch.Topic.cuda()\n",
    "        \n",
    "        predictions = model(batch.News).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.Topic)\n",
    "\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        total += batch.Topic.size(0)\n",
    "        epoch_acc += (predicted == batch.Topic).sum().item()\n",
    "        \n",
    "    return epoch_loss, epoch_acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            batch.News = batch.News.cuda()\n",
    "            batch.Topic = batch.Topic.cuda()\n",
    "            predictions = model(batch.News).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.Topic)\n",
    "            \n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total += batch.Topic.size(0)\n",
    "            epoch_acc += (predicted == batch.Topic).sum().item()\n",
    "        \n",
    "    return epoch_loss, epoch_acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 16\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_acc = 0\n",
    "\n",
    "train_loss = [0 for i in range(N_EPOCHS)]\n",
    "train_acc =[0 for i in range(N_EPOCHS)]\n",
    "test_loss = [0 for i in range(N_EPOCHS)]\n",
    "test_acc = [0 for i in range(N_EPOCHS)]\n",
    "\n",
    "i = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    train_loss[i], train_acc[i] = train(model, train_iterator, optimizer, criterion)\n",
    "    test_loss[i], test_acc[i]= evaluate(model, test_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if test_loss[i] < best_test_loss:\n",
    "        best_test_loss = test_loss[i]\n",
    "    \n",
    "    if test_acc[i] > best_test_acc:\n",
    "        best_test_acc = test_acc[i]\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss[i]:.3f} | Train Acc: {train_acc[i]*100:.2f}%')\n",
    "    print(f'\\t Test Loss: {test_loss[i]:.3f} |  Test Acc: {test_acc[i]*100:.2f}%')\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "####  News label\n",
    "    -  IT/과학': 0, '경제': 1, '문화': 2, '미용/건강': 3, '사회': 4, '생활': 5, '스포츠': 6, '연예': 7, '정치': 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(model, sentence, min_len=5):\n",
    "    model.eval()\n",
    "\n",
    "    tokenized = [tok for tok in tokenizer(sentence.split())]\n",
    "    \n",
    "    if len(tokenized) < min_len:\n",
    "      tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).unsqueeze(0).to(device)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    out = torch.mean(prediction, 0)\n",
    "    news_label = torch.max(out, 0)\n",
    "    \n",
    "    return {'Predicted Label': LABEL.vocab.itos[int(news_label.indices)], 'Acc.': news_label.values.item(), 'Sentence': sentence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래 문장의 정답은 5-8-1-2-4-6-7-3-0\n",
    "## 연예/문화, 정치/경제/사회/생활 등 명확히 구별되기 어려운 범주들이 있음...\n",
    "\n",
    "sentence = []\n",
    "sentence.append(\"차진 식감과 부드러운 감촉을 모두 지닌 식빵, 결결이 찢어지는 크루아상, 둥글고 크게 구운 호밀빵 모두 모양새부터 알차고 단단했다. 디저트로 눈을 옮기면 국가 대표팀같이 뭐 하나 빼놓을 수 없는 케이크가 나란히 줄을 서 있었다.\")\n",
    "sentence.append(\"정부는 2012년 예산의 공고안과 배정계획을 1월3일 국무회의에서 의결하고 연초부터 바로 집행에 들어간다. 세계 경제의 불확실성이 높아지고 경기가 둔화할 가능성이 높은 만큼 조기 집행에 박차를 가할 예정이다\")\n",
    "sentence.append(\"국세청은 특히 서민생활에 피해를 주면서 폭리를 취하는 매점매석 농수산물 유통업체 등에 대한 추적조사를 강화하고, 지방청에 ‘민생침해 사업자 조사전담팀’을 꾸려 민생침해 탈세자에 대한 엄정 대응에 나설 계획이라고 밝혔다\")\n",
    "sentence.append(\"26일 제25회 부산국제영화제 갈라 프레젠테이션 부문 초청작 '스파이의 아내' 온라인 기자회견이 진행됐다. 작품을 연출한 구로사와 감독이 참석해 작품에 대한 이야기를 나눴다.\")\n",
    "sentence.append(\"70대 운전사가 몰던 25인승 어린이 통학버스가 주유소로 돌진해 차량 3대를 들이 받았다. 다행히 통학버스에 운전자 외에는 탑승자가 없어 큰 인명피해는 피했다. 운전자는 차량 결함을 주장하고 있으나, 경찰은 운전자 과실 여부도 조사 중이다.\")\n",
    "sentence.append(\"토트넘이 손흥민에게 주급 20만 파운드(약 3억원)-5년 재계약을 제안할 준비를 마쳤다.' 25일(한국시각) 영국 대중일간 더선의 헤드라인이다. 조제 무리뉴 토트넘 감독이 번리전을 앞두고 기자회견을 통해 구단에 토트넘에서의 손흥민의 장밋빛 미래를 확신하며 재계약을 요청한 직후 영국 현지 언론에선 손흥민 재계약 보도가 쏟아지고 있다.\")\n",
    "sentence.append(\"공연은 말 그대로 다채로움 그 자체였다. 발레극인지, 현대무용극인지, 전통극인지, 연극인지, 연극이면 다인극인지 1인극인지 모를 정도로 다양한 장르의 결합이 먼저 눈에 띈다.\")\n",
    "sentence.append(\"발이 아프면 걷는 자세가 나빠지고 자연스럽게 무릎, 골반, 허리에 이상이 생길 수 있다. 이를 예방하려면 평소 발바닥 근육을 스트레칭하고 강화하는 운동을 지속하는 게 중요하다.\")\n",
    "sentence.append(\"전기차 화재 사고가 연이어 발생하는 가운데 불타지 않는 SK이노베이션 배터리가 주목받는다. SK이노베이션의 배터리는 글로벌 배터리 업체 중 유일하게 단 한건의 화재도 일어나지 않았다. 이같은 비결이 자동차 안정성을 결정짓는 분리막 내재화에 있다는 평가가 나온다.\")\n",
    "\n",
    "raw_data = {'Labels': ['생활','정치','경제','문화','사회','스포츠','연예','미용/건강','IT/과학']}\n",
    "\n",
    "result = pd.DataFrame(raw_data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for s in sentence:\n",
    "  df = df.append(predict_news(model, s), ignore_index=True)\n",
    "\n",
    "result = pd.concat([result,df],axis=1, join='inner')\n",
    "\n",
    "Accuracy = sum((result['Labels'] == result['Predicted Label'])==True)/len(result) * 100\n",
    "\n",
    "print(\"Accuracy = \",round(Accuracy,2),\"%\")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
